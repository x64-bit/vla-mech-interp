# Mechanistic Interpretability for Steering Vision-Language-Action Models in Simulation - pi0.5 guide

This README captures the two concept-discovery workflows covered in this repo:

1. **Activation clustering** – hook the π0/π0.5 FFNs, log the most active neurons, and group their value vectors into semantic clusters.
2. **Latent steering** – capture residual streams for contrastive concept pairs, run them through a sparse autoencoder (SAE), and derive steering vectors.

Both pipelines are designed to be completely reproducible with the scripts already checked into `src/openpi`.

For other guides, like OpenVLA usage and more specific notes on collecting latents, see `docs/`.

## Disclaimer
This README was generated by an LLM based on rough internal notes recorded during rapid prototyping and verified by human inspection. We believe it accurately reflects our current workflow, but there may be gaps or inaccuracies. Feedback, corrections, and improvements are welcome.

---

## Common Prerequisites

- **Environment:** `uv sync` inside `src/openpi`, then run commands via `uv run …` or inside the project venv.
- **Checkpoints:** Place the converted PyTorch checkpoint for your policy under `data/openpi-assets/checkpoints/<name>/model.safetensors` (or point CLI flags at your custom path).
- **Train configs:** We reused the configs in `src/openpi/src/openpi/training/config.py` (`pi0_libero_*`, `pi05_libero_*`), but any `TrainConfig` works as long as you can load the matching checkpoint.

You will also have to clone the [LIBERO repository](https://github.com/Lifelong-Robot-Learning/LIBERO) into `src/` yourself.

---

## Reproducibility & Tracked Assets

- **Tracked:** code under `src/`, docs in `docs/` and `journal/`, manifests in `data/manifests/*.json`, latent pair config `data/latent_steering/layer12_pairs.json`, utility scripts in `data/utils/`, and the finetuned SAE checkpoint `sae_finetuned/sae_pi0_layer12_finetuned.pt`.
- **Ignored (regenerate):** raw/converted LIBERO demos (`data/libero_*`), residual captures and slices (`data/residuals/**`), latent steering outputs (`data/latent_steering/**`, `data/latent_steering_finetuned/**`), rollout/eval artifacts, and heavy checkpoints under `checkpoints/`.
- **To reproduce:** re-download LIBERO demos, run conversion (`convert_libero90_data_to_lerobot.py`), build manifests (`build_contrasting_pairs.py`), map concepts, capture residuals, slice by concept, and compute steering vectors (`compute_latent_steering.py`). OpenVLA steering experiments follow `docs/open_vla_steering.md` (extract → project → cluster → build/apply steering → evaluate).
- **Residual note:** raw residual captures are not tracked; regenerate by rerunning `openpi.analysis.save_residuals` and `scripts/slice_residuals_by_concept.py` using the provided manifests/concept maps and pair config.
- **Checkpoints note:** the `pi0_libero_*` configs in `src/openpi/src/openpi/training/config.py` reference a `gs://openpi-assets/checkpoints/pi0_base/params` loader. If you do not have that GCS bucket, point the loader to your local pi0 checkpoint or an equivalent HF model path.
- **File size note:** some per-concept slices (e.g., `data/residuals/*_slices/layer12/*.pt`) can exceed GitHub’s 50 MB warning/100 MB hard limit. If needed, store them elsewhere (artifact store or LFS) and regenerate locally via the scripts above.

---

## 1. Activation Clustering Pipeline

### 1.1 Dump observation batches

`scripts/extract_ffn_vectors.py` consumes `.npz` files where each file stores a dict compatible with `policy.infer`. We typically dump them straight from a Libero dataloader:

```bash
uv run python - <<'PY'
import pathlib, numpy as np
from openpi.training import config as train_config, data_loader

OUTPUT = pathlib.Path("data/activation_records/pi05_libero_open_close")
OUTPUT.mkdir(parents=True, exist_ok=True)

cfg = train_config.get_config("pi05_libero_open_close")
loader = data_loader.create_data_loader(
    cfg, framework="pytorch", shuffle=False, num_batches=256, skip_norm_stats=False
)

for idx, (obs, _) in enumerate(loader):
    path = OUTPUT / f"batch_{idx:04d}.npz"
    np.savez_compressed(path, obs.to_dict())
    if idx == 255:
        break
PY
```

*Tips*
- Pass `--lerobot-home` or set `HF_LEROBOT_HOME` if your LeRobot datasets live outside the repo.
- Use fewer batches while iterating; the probe only needs ~100–200 batches to surface strong neurons.

### 1.2 Extract FFN projections

```bash
uv run python src/openpi/scripts/extract_ffn_vectors.py \
  --config-name pi05_libero_open_close \
  --checkpoint-dir data/openpi-assets/checkpoints/pi05_libero_open_close \
  --observations-glob "data/activation_records/pi05_libero_open_close/*.npz" \
  --output-path data/activation_records/pi05_open_close_ffn.json \
  --top-k-per-layer 32 \
  --max-batches 200 \
  --store-value-vectors \
  --min-activation 0.6 \
  --device cuda
```

This hooks every Gemma MLP down-projection, tracks the max absolute activation per neuron, and dumps JSON entries like:

```json
{
  "layer_index": 12,
  "neuron_index": 745,
  "max_activation": 1.98,
  "top_tokens": [{"token": "▁open", "logit": 7.3}, …],
  "value_vector": [...]
}
```

We checked our run into `test_outputs/test_ffn_projections.json` for quick smoke-tests.

### 1.3 Cluster neurons

```bash
uv run python src/openpi/scripts/cluster_ffn_vectors.py \
  --projections-path data/activation_records/pi05_open_close_ffn.json \
  --output-path data/activation_records/pi05_open_close_clusters.json \
  --num-clusters 40 \
  --normalize \
  --random-seed 42 \
  --keywords open close drawer \
  --use-semantic-space \
  --model-checkpoint data/openpi-assets/checkpoints/pi05_libero_open_close/model.safetensors \
  --model-config data/openpi-assets/checkpoints/pi05_libero_open_close/config.json \
  --top-k-tokens 20 \
  --device cuda
```

Key options:

- `--use-semantic-space` projects each value vector through the LM head and averages top token embeddings, which made the drawer clusters separate more cleanly than raw weight space.
- `--keywords …` prints a ranked list so you can immediately spot clusters whose decoded tokens mention “open/close”, “stove”, etc.
- Restrict to specific layers with `--layers 12 13` if you only care about the paligemma block we probed.

### 1.4 Post-processing

Outputs land under:

- `data/activation_records/*.json` – raw projections and clustered membership lists.
- `test_outputs/cluster_tsne_visualization.png` – optional t-SNE plot if you run `python src/openpi/src/openpi/cluster_test.py`.

You can feed `pi05_open_close_clusters.json` into whatever downstream tooling you like (e.g., steering configs or notebooks).

---

## 2. Latent Concept Steering Pipeline

This section unifies everything from `docs/latent_steering_pipeline.md` plus the new custom suite catalog in `src/openpi/docs/custom_suites.md`.

### 2.1 Convert & filter Libero data

Start from the Libero `.hdf5` demos and convert them to LeRobot format for each binary concept pair (open/close, on/off, front/back):

```bash
uv run src/openpi/examples/libero/convert_libero90_data_to_lerobot.py \
  --args.input-dir data/libero_filtered/open_close \
  --args.repo-id libero_open_close_lerobot \
  --args.output-dir data/libero_lerobot/libero_open_close_lerobot
```

We keep the filtered folders (`data/libero_filtered/*`) so the exact demo subset is documented.
Why filter the raw `.hdf5` first instead of starting from a LeRobot dump?
- Manifest generation expects direct access to the raw Libero states (the LeRobot export hides some fields and is heavier to index), so we pick the exact `.hdf5` demos before conversion.
- Lets us pin an exact subset of demos per concept pair (e.g., only the drawer tasks) so downstream manifests/maps stay reproducible.
- Keeps storage small; the full Libero → LeRobot export is large, but the filtered copy contains only the demos we need.
- Avoids re-downloading/hosting converted LeRobot tarballs; anyone can re-download the original Libero demos and rerun the same filter/convert step.
- If you want the full dataset, skip the filter step and point `--input-dir` at the complete Libero folder.

### 2.2 Build contrast manifests

```bash
python data/utils/build_contrasting_pairs.py \
  --backend lerobot \
  --lerobot-root data/libero_lerobot/libero_open_close_lerobot \
  --task-a-text "open the top drawer of the cabinet" \
  --task-b-text "close the top drawer of the cabinet" \
  --output data/manifests/open_vs_close.json
```

Repeat for:

- `on_vs_off.json`
- `open_vs_close_front_back.json`
- `back_vs_front.json`

Each manifest contains 100 segments (50 per concept) plus the axis stats we summarized via `python - <<'PY' …` (see `custom_suites.md`).
What the script does:
- Loads the LeRobot repo, finds the state axis with the largest effect size between the two task texts, and proposes 50 windows per concept along that axis.
- Writes per-window start/end indices plus summary statistics (`axis_index`, `effect_size`, window lengths) to JSON.
- Uses only the repo/task strings you pass; nothing else is needed beyond the converted demos.

Tips:
- Keep `--backend lerobot` unless you add another backend.
- Set `--task-a-text/--task-b-text` to the exact instruction strings you will later pass to slicing/steering so filenames line up.
- You can tweak sample counts via `--segments-per-class` if you want more/less than 50.

### 2.3 Map segments to dataset indices

```bash
python src/openpi/scripts/map_concept_samples.py \
  --manifest-path data/manifests/open_vs_close.json \
  --output-path data/manifests/open_vs_close_concept_map.json \
  --lerobot-root data/libero_lerobot/libero_open_close_lerobot \
  --repo_id libero_open_close_lerobot
```

The concept maps let us line up manifest segments with precise episode indices during slicing.
Details:
- Input: a manifest JSON, the LeRobot repo root, and the repo ID (must match what was used during conversion).
- Output: `<suite>_concept_map.json` that adds dataset indices (`episode`, `start`, `end`) for every window so slicing scripts can load the right tensors.
- Run once per suite; downstream steps (residual capture and slicing) consume the map directly.

### 2.4 Capture residuals

```bash
python -m openpi.analysis.save_residuals \
  --args.checkpoint-path data/openpi-assets/checkpoints/pi05_libero_open_close/model.safetensors \
  --args.config-name pi05_libero_open_close \
  --args.output-dir data/residuals/open_close_run \
  --args.layers 12 \
  --args.batch-size 128 \
  --args.capture-instructions \
  --args.samples-per-file 4096 \
  --args.max-samples-per-layer 50000 \
  --args.device cuda
```

Artifacts:

- Decision tokens → `data/residuals/open_close_run/decision/layer12_chunk*.pt`
- Instruction tokens → `data/residuals/open_close_run/instructions/layer12_chunk*.pt`
- Metadata → `data/residuals/open_close_run/metadata.json`

We repeated this for `open_close_front_back_run` to match the harder workspace.

### 2.5 Slice by concept

```bash
python src/openpi/scripts/slice_residuals_by_concept.py \
  --run-dir data/residuals/open_close_run \
  --concept-map-path data/manifests/open_vs_close_concept_map.json \
  --output-dir data/residuals/open_vs_close_slices \
  --token-type instructions \
  --layers 12 \
  --device cpu
```

This writes tensors like `data/residuals/open_vs_close_slices/layer12/open the top drawer of the cabinet.pt`, one per concept.

### 2.6 Define pair config

Edit `data/latent_steering/layer12_pairs.json` (already populated with our four suites) to point at the freshly sliced files. Example entry:

```json
{
  "name": "open_vs_close",
  "positive_label": "open the top drawer of the cabinet",
  "positive_path": "data/residuals/open_vs_close_slices/layer12/open the top drawer of the cabinet.pt",
  "negative_label": "close the top drawer of the cabinet",
  "negative_path": "data/residuals/open_vs_close_slices/layer12/close the top drawer of the cabinet.pt"
}
```

### 2.7 Compute latent directions

```bash
python src/openpi/scripts/compute_latent_steering.py \
  --args.pairs-config data/latent_steering/layer12_pairs.json \
  --args.output-root data/latent_steering \
  --args.layer 12 \
  --args.device cuda \
  --args.batch-size 512 \
  --args.sae-release gemma-2b-it-res-jb \
  --args.finetuned-sae-path sae_finetuned/sae_pi0_layer12_finetuned.pt
```

Outputs per pair under `data/latent_steering/layer12/<pair>/`:

- `positive_latent_mean.pt` & `negative_latent_mean.pt`
- `latent_direction.pt` (difference vector)
- `residual_direction.pt` (decoded direction)

Cross-pair cosine stats and summary plot land at:
- Base SAE: `data/latent_steering/layer12/pairwise_stats.pt` and `layer12_pairwise_summary.png`.
- Finetuned SAE: `data/latent_steering_finetuned/layer12/pairwise_stats.pt` and `layer12_pairwise_summary.png`.
Directional comparison PNGs (per pair and cross-pair) also live under each of those directories.

Optional: quick cosine bar plot between two saved steering directions:

```bash
python src/openpi/scripts/plot_steering_cosine.py \
  --vector-a.label open_vs_close \
  --vector-a.latent-path data/latent_steering/layer12/open_vs_close/latent_direction.pt \
  --vector-a.residual-path data/latent_steering/layer12/open_vs_close/residual_direction.pt \
  --vector-b.label on_vs_off \
  --vector-b.latent-path data/latent_steering/layer12/on_vs_off/latent_direction.pt \
  --vector-b.residual-path data/latent_steering/layer12/on_vs_off/residual_direction.pt \
  --output-path data/analysis/steering_cosine.png
```

### 2.8 Compare concept similarity across spaces (optional)

Run `src/openpi/scripts/compare_concept_similarity.py` to quantify how concept vectors align across residual space, SAE-decoded space, and token/semantic space, using cluster centroids as anchors.

Inputs:
- `--concept-config`: JSON mapping concept names to residual/latent file stems, keywords, and optional cluster ids.
- `--haon_residual_dir`: sliced residuals (e.g., `data/residuals/<suite>_slices`).
- `--sae_decoded_dir`: SAE-decoded residual directions (e.g., `data/latent_steering/layer12/<pair>`).
- `--haon_clusters_path`: clustered FFN centroids JSON if you want centroid comparisons.
- `--checkpoint_path` + `--config_name`: to load LM head/token embeddings for token-space projections.

Outputs:
- JSON report (default `analysis/concept_similarity.json`) with cosine overlaps for residual and token space, plus per-concept norms.
- Optional vector dumps if you pass `--vector_dump_dir`.

### 2.9 Reference catalog

See `src/openpi/docs/custom_suites.md` for a table that ties each suite to its repo, manifests, sample counts, and residual directories. That document stays in sync with the steps above so future runs can reuse our assets.

---

## 3. Suggested Validation Steps

- **Activation pipeline:** run `python src/openpi/src/openpi/cluster_test.py` to ensure the projections file is well-formed and to generate quick t-SNE visualizations.
- **Latent pipeline:** inspect `data/latent_steering/layer12_pairwise_summary.png` and the cosine comparison PNGs in `data/latent_steering_finetuned/layer12/` to confirm directions align with expectations (open vs close should anticorrelate with on vs off, etc.).
- **Bookkeeping:** keep `journal/*.md` updated with the commands you ran (see `journal/2025-12-06-latent-steering.md` for our latest log) so each experiment has a paper trail.
